"""
The model codes below are generated by GPT 3.5. Use with caution
"""
import time

import torch
import torch.nn as nn
import torch.utils.data as tud
import matplotlib.pyplot as plt


class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(10, 10)
        self.relu1 = nn.ReLU()
        # self.fc2 = nn.Linear(20, 20)
        # self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(10, 5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu1(x)
        # x = self.fc2(x)
        # x = self.relu2(x)
        x = self.fc3(x)
        return x


def train(model, train_loader, optimizer, criterion, device, risk_averse=False, quantile=0.5):
    model.train()
    for data, target in train_loader:
        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        output = model(data)

        # Calculate risk-aware loss
        threshold = torch.kthvalue(torch.sqrt(torch.mean((target - output) ** 2, dim=1)),
                                   int(target.shape[0] / 2)).values

        sample_loss = torch.sqrt(torch.mean((output - target) ** 2, dim=1))
        assert sample_loss.size(0) == data.size(0)
        if risk_averse:
            q = torch.quantile(sample_loss, quantile)
            valid_loss = sample_loss[sample_loss > q]
            train_loss = torch.sum(valid_loss) / valid_loss.size(0)
        else:
            train_loss = torch.sum(sample_loss) / data.size(0)

        reg_loss = 0
        for param in model.parameters():
            reg_loss += torch.norm(param, p=2)
        # this 0.01 should be seen as a hyperparam as well
        train_loss += 0.01 * reg_loss

        train_loss.backward()
        optimizer.step()

    eval_loss = evaluate(model, train_loader, device, risk_averse, quantile)
    return eval_loss


def evaluate(model, data_loader, device, risk_averse=False, quantile=0.5):
    model.eval()
    losses = []

    with torch.no_grad():
        for data, target in data_loader:
            data, target = data.to(device), target.to(device)

            output = model(data)
            sample_loss = torch.sqrt(torch.mean((output - target) ** 2, dim=1))
            if risk_averse:
                q = torch.quantile(sample_loss, quantile)
                valid_loss = sample_loss[sample_loss > q]
                eval_loss = torch.sum(valid_loss) / valid_loss.size(0)
            else:
                eval_loss = torch.sum(sample_loss) / data.size(0)

            losses.append(eval_loss)

        avg_loss = torch.Tensor(losses).mean()
    return avg_loss


if __name__ == '__main__':
    # Create dataset and dataloader
    train_X = torch.randn(1000, 10)
    train_y = train_X[:, :5]
    train_dataset = tud.TensorDataset(train_X, train_y)
    train_loader = tud.DataLoader(train_dataset, batch_size=128)

    test_X = torch.randn(200, 10)
    test_y = test_X[:, :5]
    test_dataset = tud.TensorDataset(test_X, test_y)
    test_loader = tud.DataLoader(test_dataset, batch_size=128)

    # Initialize model, optimizer, and loss function
    model_a = MLP()
    op_a = torch.optim.Adam(model_a.parameters(), lr=5e-3)

    model_b = MLP()
    op_b = torch.optim.Adam(model_b.parameters(), lr=5e-3)

    criterion = nn.MSELoss()

    # Train the model for 100 epochs
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print("training using GPU")
    else:
        device = torch.device("cpu")
        print("training using CPU")

    model_a.to(device)
    model_b.to(device)

    a_losses, b_losses = [], []
    for epoch in range(100):
        time_a = time.time()
        ev_loss_a = train(model_a, train_loader, op_a, criterion, device)
        ev_loss_b = train(model_b, train_loader, op_b, criterion, device, risk_averse=True, quantile=0.9)
        a_losses.append(ev_loss_a)
        b_losses.append(ev_loss_b)
        print("Epoch {}: Eval Loss a = {:.4f}, b = {:.4f}, Run Time = {}".format
              (epoch + 1, ev_loss_a, ev_loss_b, time.time() - time_a))

    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)

    ax1.plot(a_losses, label="model_a")
    ax1.plot(b_losses, label="model_b", color="red")
    ax1.set_title("Training eval loss curves")
    ax1.set_xlabel("iteration")
    ax1.set_ylabel("train loss")
    ax1.legend()

    # get 10 quantiles for testing
    quantiles = torch.linspace(0.05, 0.95, 10).tolist()
    a_test_loss, b_test_loss = [], []

    for quantile in quantiles:
        a_test_loss.append(evaluate(model_a, test_loader, device, risk_averse=True, quantile=quantile))
        b_test_loss.append(evaluate(model_b, test_loader, device, risk_averse=True, quantile=quantile))

    ax2.plot(a_test_loss, label="model_a")
    ax2.plot(b_test_loss, label="model_b", color="red")
    ax2.set_title("Testing error at different qs")
    ax2.set_xlabel("quantiles")
    ax2.set_ylabel("test loss")
    ax2.legend()
    plt.show()